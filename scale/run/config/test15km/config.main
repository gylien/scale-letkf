#!/bin/bash
#===============================================================================
#
#  Main settings for SCALE-LETKF scripts
#
#===============================================================================

#PRESET='K_rankdir'                          # 'K' or 'K_rankdir' or 'K_micro'
PRESET='K_micro'

EXP="test15km"

USERNAME=honda

# -- H08 --
# -- RTTOV_DIR --
DIR_RTTOV=/volume64/data/ra001011/honda/RTTOV12.2
RTTOV_COEF=${DIR_RTTOV}/rtcoef_rttov12/rttov7pred54L/rtcoef_himawari_8_ahi.dat
RTTOV_SCCOEF=${DIR_RTTOV}/rtcoef_rttov12/cldaer_ir/sccldcoef_himawari_8_ahi.dat


INDIR="/volume64/data/ra001011/tnecker/experiments/germany_15km_3h_en_cycle_1000m"
OUTDIR="/volume64/data/ra001011/${USERNAME}/SCALE-LETKF/VIS_TEST/OUTPUT/${EXP}"

#===============================================================================
# Location of model/data files

MODELDIR="$DIR/../../bin"                                            # Directory of the SCALE model executables
DATADIR="/volume64/data/ra001011/tnecker/database"                   # Directory of the SCALE database
DATA_TOPO=                                                           # Directory of the prepared topo files
DATA_TOPO_BDY_SCALE=
DATA_LANDUSE=                                                        # Directory of the prepared landuse files
DATA_BDY_SCALE=                                                      # Directory of the boundary data in SCALE history format (parent domain)
DATA_BDY_SCALE_PREP=                                                 # Directory of the prepared SCALE boundary files
DATA_BDY_WRF='/volume64/data/ra001011/jruiz/input_data/wrf_files/SCALE_BDY_EUROPE_50K_scale_boundary_prep_1000mem/scale_bdy/'
#DATA_BDY_WRF='/volume64/data/ra001011/tnecker/bdy_scale_ens/scale_bdy/'
#DATA_BDY_WRF="/volume64/data/ra001011/gstefan/EXPERIMENTS/SCALE_BDY_EUROPE_50K_scale_boundary_prep_europe_lowres_1000m/scale_bdy/"   # Directory of the boundary data in WRF format
DATA_BDY_NICAM=                                                      # Directory of the boundary data in NICAM format (not finished)
#DATA_BDY_GRADS="$DDIR/ncepfnl_grads"                                 # Directory of the boundary data in GrADS format

OBS="/volume64/data/ra001011/gstefan/OBS/prepbufr_europe_scale/scale_3hr/"                  # Observation data in LETKF observation format
OBSNCEP=

#===============================================================================
# model/data file options TOPO_FORMAT and following should be GTOP030 byw. GLCCv2

TOPO_FORMAT='prep'      # 'prep': Use prepared topo files in $DATA_TOPO
                        # 'GTOPO30' (requires compatible 'config.nml.scale_pp')
                        # 'DEM50M'  (requires compatible 'config.nml.scale_pp')

LANDUSE_FORMAT='prep'   # 'prep': Use prepared landuse files in $DATA_LANDUSE
                        # 'GLCCv2' (requires compatible 'config.nml.scale_pp')
                        # 'LU100M' (requires compatible 'config.nml.scale_pp')
LANDUSE_UPDATE=0        # 0: Time-invariant landuse files
                        # 1: Time-variant landuse files

BDY_FORMAT=2            # 0: SCALE boundary files (with exactly same domain settings; do not need additional preprocessing)
                        # 1: SCALE history (requires compatible 'config.nml.scale_init')
                        # 2: WRF           (requires compatible 'config.nml.scale_init')
                        # 3: NICAM         (requires compatible 'config.nml.scale_init')
                        # 4: GrADS         (requires compatible 'config.nml.scale_init')
BDY_SINGLE_FILE=0       # 0: Length of a boundary file = $BDYCYCLE_INT (e.g., files made by data assimilation cycles)
                        # 1: Length of a boundary file is long enough so that only a single boundary file is used for each forecast
BDY_SCALE_DIR='hist'    # Directory name of the SCALE history files when $BDY_FORMAT = 1

BDY_ENS=1               # 0: Fixed boundary files for all memebers
                        # 1: Ensemble boundary files
BDY_ROTATING=0          # 0: Use a same series of boundary files for all initial time
                        # 1: Use different series of boundary files for different initial time

BDYINT=21600		#for small domain set it to 1h frequency!!	
BDYCYCLE_INT=21600	#for small domain set it to 6 h frequency!!

PARENT_REF_TIME=20160601060000 #20160605180000

ENABLE_PARAM_USER=1     # 0: Do not enable the 'PARAM_USER' section of the SCALE namelist
                        # 1: Enable the 'PARAM_USER' section of the SCALE namelist (require 'config.nml.scale_user' and customized version of SCALE)

OCEAN_INPUT=1           # 0: No ocean input (use cycling ocean variables)
                        # 1: Update the ocean variables every cycle
OCEAN_FORMAT=99         # 0: SCALE init files (with exactly same domain settings; do not need additional preprocessing)
                        # 99: From the same file as used in generating the boundary conditions ($BDY_FORMAT)
LAND_INPUT=1            # 0: No land input (use cycling land variables)
                        # 1: Update the land variables every cycle
LAND_FORMAT=99          # 0: SCALE init files (with exactly same domain settings; do not need additional preprocessing)
                        # 99: From the same file as used in generating the boundary conditions ($BDY_FORMAT)

OBSNUM=1
OBSNAME[1]=obs                                    
OBSNAME[2]=radar
OBSOPE_SEPARATE[1]=0
OBSOPE_SEPARATE[2]=0

#===============================================================================
# Cycling settings

WINDOW_S=3600     # SCALE forecast time when assimilation window starts (second)
WINDOW_E=14400     # SCALE forecast time when assimilation window ends (second)
LCYCLE=10800       # Length of a GFS-LETKF cycle (second)
LTIMESLOT=3600     # Timeslot interval for 4D-LETKF (second)

#===============================================================================
# Parallelization settings

MEMBER=1000 #1000  # Ensemble size

NNODES=1600 #4008  # Number of nodes = member * scale_np + scale_np
NNODES=8 #
PPN=1              # Number of processes per node

THREADS=8          # Number of threads per process

SCALE_NP=8         # Number of processes to run SCALE

BGJOB_INT='0.1s'   # Interval of multiple background job submissions

#ENABLE_SET=1       ######

#===============================================================================
# Temporary directories to store runtime files

DATA_BDY_TMPLOC=1           # Location of the temporary directory for DATA_BDY
                            #  1: in $TMPDAT
                            #  2: in $TMPOUT

DISK_MODE_TOPO_LANDUSE_DB=2

DISK_MODE_DATA_BDY=2

DISK_MODE_DATA_TOPO=2
DISK_MODE_DATA_LANDUSE=2
DISK_MODE_DATA_BDYPREP=2

ONLINE_STGOUT=0             # Stage out right after each cycle (do not wait until the end of the job)?
                            #  0: No
                            #  1: Yes

#SIMPLE_STGOUT=1             # Stage out the entire 'out' temporary directory instead of specifying each file?
#                            #  0: No
#                            #  1: Yes

SYSNAME="$(basename $OUTDIR)"                # A unique name in the machine
TMPSUBDIR="scale-letkf_${SYSNAME}" # (used to identify multiple runs in the same time)

TMP="/scratch/$(echo $(id -ng)|cut -c 1-8)/${USERNAME}/$TMPSUBDIR" # Temporary directory shared among all nodes
TMPS="$DIR/tmp/$TMPSUBDIR"  # Temporary directory only on the server node
#TMPL=

CLEAR_TMP=0                 # Clear temporary directories after the completion of job?
                            #  0: No
                            #  1: Yes

#===============================================================================
# Environmental settings

MPIRUN="mpiexec"
if (which $MPIRUN > /dev/null 2>&1); then
  MPIRUN=$(which $MPIRUN)
fi


SCP='cp -L'
SCP_HOSTPREFIX=''
#SCP="scp -q"
#SCP_HOSTPREFIX="XXXX:"

SCP_THREAD=8
TAR_THREAD=8

PYTHON="python"

#BUFRBIN=

#===============================================================================
# Machine-independent source file

. config.rc

#===============================================================================
